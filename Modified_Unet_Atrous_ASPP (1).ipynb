{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyPlon_-DC5n"
      },
      "outputs": [],
      "source": [
        "#REPLACE THE ORIGINAL CONVOLUTION LAYERS WITH THE MULTI-SCALE RESIDUAL ATROUS CONVOLUTION AND \n",
        "#ADD MULTI-LEVEL RESIDUAL ATROUS SPATIAL PYRAMID POOLING MODULES BETWEEN THE ENCODING AND DECODING MODULES."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqlN3olXRghu",
        "outputId": "a2b87659-5fa9-4759-b2ab-e53d8d2a97c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MSRAC_MLRASPP_UNET\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 512, 512, 64  256         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 512, 512, 64  256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 512, 512, 64  0           ['batch_normalization_2[0][0]',  \n",
            "                                )                                 'batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 512, 512, 64  0           ['add[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 256, 256, 12  8320        ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 256, 256, 12  512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 256, 256, 12  512        ['conv2d_4[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 256, 256, 12  0           ['batch_normalization_5[0][0]',  \n",
            "                                8)                                'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 256, 256, 12  0           ['add_1[0][0]']                  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_6[0][0]']  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 128, 128, 25  33024       ['max_pooling2d_1[0][0]']        \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_8[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   6)                                                                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 128, 128, 25  0           ['batch_normalization_8[0][0]',  \n",
            "                                6)                                'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 128, 128, 25  0           ['add_2[0][0]']                  \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 64, 64, 512)  131584      ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 64, 64, 512)  0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 1024  4096       ['conv2d_12[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_12[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 1024  525312      ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 1024  4096       ['conv2d_14[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 1024  4096       ['conv2d_13[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 32, 1024  0           ['batch_normalization_14[0][0]', \n",
            "                                )                                 'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 32, 32, 1024  0           ['add_4[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 1024)  0           ['activation_9[0][0]']           \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 1, 1, 512)    524288      ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 512)  524288      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 32, 32, 512)  4718592     ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 32, 32, 512)  4718592     ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 32, 512)  4718592     ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 32, 32, 512)  0           ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 2560  0           ['up_sampling2d[0][0]',          \n",
            "                                )                                 'activation_11[0][0]',          \n",
            "                                                                  'activation_12[0][0]',          \n",
            "                                                                  'activation_13[0][0]',          \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 32, 32, 512)  1310720     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  1049088    ['activation_15[0][0]']          \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 64, 64, 512)  524800      ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 64, 64, 512)  0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 64, 512)  0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_17[0][0]']          \n",
            " spose)                         6)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                2)                                'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_2[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 128, 128, 25  1024       ['conv2d_28[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_28[0][0]'] \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 128, 128, 25  131328      ['concatenate_2[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 128, 128, 25  590080      ['activation_18[0][0]']          \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 128, 128, 25  1024       ['conv2d_30[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 128, 128, 25  1024       ['conv2d_29[0][0]']              \n",
            " ormalization)                  6)                                                                \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 128, 128, 25  0           ['batch_normalization_30[0][0]', \n",
            "                                6)                                'batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 128, 128, 25  0           ['add_10[0][0]']                 \n",
            "                                6)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_19[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_3[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 256, 256, 12  512        ['conv2d_31[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_31[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 256, 256, 12  32896       ['concatenate_3[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 256, 256, 12  147584      ['activation_20[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 256, 256, 12  512        ['conv2d_33[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 256, 256, 12  512        ['conv2d_32[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 256, 256, 12  0           ['batch_normalization_33[0][0]', \n",
            "                                8)                                'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 256, 256, 12  0           ['add_11[0][0]']                 \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_21[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 512, 512, 64  256        ['conv2d_34[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_34[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 512, 512, 64  8256        ['concatenate_4[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 512, 512, 64  36928       ['activation_22[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 512, 512, 64  256        ['conv2d_36[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 512, 512, 64  256        ['conv2d_35[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 512, 512, 64  0           ['batch_normalization_36[0][0]', \n",
            "                                )                                 'batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 512, 512, 64  0           ['add_12[0][0]']                 \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 512, 512, 1)  65          ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 47,941,633\n",
            "Trainable params: 47,917,825\n",
            "Non-trainable params: 23,808\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#model residual atrous convolution  + ASPP\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np,sys\n",
        "from  scipy.signal import convolve2d\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.layers import Conv2D,  UpSampling2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, AveragePooling2D, Concatenate, Input, GlobalAveragePooling2D, Reshape, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", dilation_rate = (2,2))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", dilation_rate = (4,4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    shortcut = Conv2D(num_filters, 1, padding =\"same\") (inputs)         #RESIDUAL\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    \n",
        "    x= tf.keras.layers.add([shortcut, x])\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    s = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(s)\n",
        "    return s, p\n",
        "\n",
        "def ASPP(inputs):\n",
        "    \"\"\" Image Pooling \"\"\"\n",
        "    shape = inputs.shape\n",
        "    y1 = AveragePooling2D(pool_size=(shape[1], shape[2]))(inputs)\n",
        "    y1 = Conv2D(512, 1, padding=\"same\", use_bias=False)(y1)\n",
        "    y1 = BatchNormalization()(y1)\n",
        "    y1 = Activation(\"relu\")(y1)\n",
        "    y1 = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y1)\n",
        "\n",
        "    \"\"\" 1x1 conv \"\"\"\n",
        "    y2 = Conv2D(512, 1, padding=\"same\", use_bias=False)(inputs)\n",
        "    y2 = BatchNormalization()(y2)\n",
        "    shortcut = Conv2D(512, 1, padding =\"same\") (inputs)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x= tf.keras.layers.add([shortcut, y2])\n",
        "    y2 = Activation(\"relu\")(y2)\n",
        "\n",
        "    \"\"\" 3x3 conv rate=6 \"\"\"\n",
        "    y3 = Conv2D(512, 3, padding=\"same\", use_bias=False, dilation_rate=6)(inputs)\n",
        "    y3 = BatchNormalization()(y3)\n",
        "    shortcut = Conv2D(512, 3, padding =\"same\") (inputs)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x= tf.keras.layers.add([shortcut, y3])\n",
        "    y3 = Activation(\"relu\")(y3)\n",
        "\n",
        "    \"\"\" 3x3 conv rate=12 \"\"\"\n",
        "    y4 = Conv2D(512, 3, padding=\"same\", use_bias=False, dilation_rate=12)(inputs)\n",
        "    y4 = BatchNormalization()(y4)\n",
        "    shortcut = Conv2D(512, 3, padding =\"same\") (inputs)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x= tf.keras.layers.add([shortcut, y4])\n",
        "    y4 = Activation(\"relu\")(y4)\n",
        "\n",
        "    \"\"\" 3x3 conv rate=18 \"\"\"\n",
        "    y5 = Conv2D(512, 3, padding=\"same\", use_bias=False, dilation_rate=18)(inputs)\n",
        "    y5 = BatchNormalization()(y5)\n",
        "    shortcut = Conv2D(512, 3, padding =\"same\") (inputs)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "    x= tf.keras.layers.add([shortcut, y5])\n",
        "    y5 = Activation(\"relu\")(y5)\n",
        "\n",
        "    y = Concatenate()([y1, y2, y3, y4, y5])\n",
        "    y = Conv2D(512, 1, padding=\"same\", use_bias=False)(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation(\"relu\")(y)\n",
        "\n",
        "    return y\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    \"\"\"input layer\"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\"Encoder\"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    \"\"\"Bottleneck\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "    A = ASPP(b1)\n",
        "\n",
        "    \"\"\"Decoedr\"\"\"\n",
        "    d1 = decoder_block(A, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"MSRAC_MLRASPP_UNET\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (512, 512, 3)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jdBvogvDPSf"
      },
      "outputs": [],
      "source": [
        "#Metrics\n",
        "from tqdm import tqdm\n",
        "import imageio\n",
        "from albumentations import HorizontalFlip, VerticalFlip, ElasticTransform, Transpose, RandomRotate90, GridDistortion, OpticalDistortion, CoarseDropout\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzD5E-ZDPVH",
        "outputId": "4b9935d0-1c48-4f6c-82f5-f3a6edd2f2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 160 - 160\n",
            "Valid: 20 - 20\n",
            "Epoch 1/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.4480 - dice_coef: 0.5520 - iou: 0.3892 - recall: 0.3137 - precision: 0.6972\n",
            "Epoch 1: val_loss improved from inf to 0.83210, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 210s 4s/step - loss: 0.4480 - dice_coef: 0.5520 - iou: 0.3892 - recall: 0.3137 - precision: 0.6972 - val_loss: 0.8321 - val_dice_coef: 0.1679 - val_iou: 0.0918 - val_recall: 0.2554 - val_precision: 0.2683 - lr: 0.0010\n",
            "Epoch 2/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3425 - dice_coef: 0.6575 - iou: 0.4914 - recall: 0.2853 - precision: 0.8717\n",
            "Epoch 2: val_loss improved from 0.83210 to 0.79905, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.3425 - dice_coef: 0.6575 - iou: 0.4914 - recall: 0.2853 - precision: 0.8717 - val_loss: 0.7990 - val_dice_coef: 0.2010 - val_iou: 0.1120 - val_recall: 0.8651 - val_precision: 0.2841 - lr: 0.0010\n",
            "Epoch 3/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.3142 - dice_coef: 0.6858 - iou: 0.5233 - recall: 0.2893 - precision: 0.8992\n",
            "Epoch 3: val_loss did not improve from 0.79905\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.3142 - dice_coef: 0.6858 - iou: 0.5233 - recall: 0.2893 - precision: 0.8992 - val_loss: 0.9876 - val_dice_coef: 0.0124 - val_iou: 0.0062 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 4/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2960 - dice_coef: 0.7040 - iou: 0.5443 - recall: 0.2946 - precision: 0.9131\n",
            "Epoch 4: val_loss did not improve from 0.79905\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2960 - dice_coef: 0.7040 - iou: 0.5443 - recall: 0.2946 - precision: 0.9131 - val_loss: 0.9283 - val_dice_coef: 0.0717 - val_iou: 0.0373 - val_recall: 0.0135 - val_precision: 0.3372 - lr: 0.0010\n",
            "Epoch 5/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2817 - dice_coef: 0.7183 - iou: 0.5614 - recall: 0.2988 - precision: 0.9234\n",
            "Epoch 5: val_loss did not improve from 0.79905\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2817 - dice_coef: 0.7183 - iou: 0.5614 - recall: 0.2988 - precision: 0.9234 - val_loss: 0.9448 - val_dice_coef: 0.0552 - val_iou: 0.0284 - val_recall: 0.0081 - val_precision: 0.6071 - lr: 0.0010\n",
            "Epoch 6/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2717 - dice_coef: 0.7283 - iou: 0.5734 - recall: 0.3012 - precision: 0.9307\n",
            "Epoch 6: val_loss did not improve from 0.79905\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2717 - dice_coef: 0.7283 - iou: 0.5734 - recall: 0.3012 - precision: 0.9307 - val_loss: 0.8214 - val_dice_coef: 0.1786 - val_iou: 0.0988 - val_recall: 0.0402 - val_precision: 0.6584 - lr: 0.0010\n",
            "Epoch 7/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2652 - dice_coef: 0.7348 - iou: 0.5814 - recall: 0.3039 - precision: 0.9338\n",
            "Epoch 7: val_loss improved from 0.79905 to 0.73595, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 73s 2s/step - loss: 0.2652 - dice_coef: 0.7348 - iou: 0.5814 - recall: 0.3039 - precision: 0.9338 - val_loss: 0.7360 - val_dice_coef: 0.2640 - val_iou: 0.1532 - val_recall: 0.0708 - val_precision: 0.5783 - lr: 0.0010\n",
            "Epoch 8/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2624 - dice_coef: 0.7376 - iou: 0.5850 - recall: 0.3039 - precision: 0.9364\n",
            "Epoch 8: val_loss improved from 0.73595 to 0.66822, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.2624 - dice_coef: 0.7376 - iou: 0.5850 - recall: 0.3039 - precision: 0.9364 - val_loss: 0.6682 - val_dice_coef: 0.3318 - val_iou: 0.2005 - val_recall: 0.0898 - val_precision: 0.6843 - lr: 0.0010\n",
            "Epoch 9/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2542 - dice_coef: 0.7458 - iou: 0.5952 - recall: 0.3062 - precision: 0.9426\n",
            "Epoch 9: val_loss improved from 0.66822 to 0.54008, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 74s 2s/step - loss: 0.2542 - dice_coef: 0.7458 - iou: 0.5952 - recall: 0.3062 - precision: 0.9426 - val_loss: 0.5401 - val_dice_coef: 0.4599 - val_iou: 0.3007 - val_recall: 0.1658 - val_precision: 0.6142 - lr: 0.0010\n",
            "Epoch 10/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2485 - dice_coef: 0.7515 - iou: 0.6024 - recall: 0.3077 - precision: 0.9460\n",
            "Epoch 10: val_loss improved from 0.54008 to 0.48936, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.2485 - dice_coef: 0.7515 - iou: 0.6024 - recall: 0.3077 - precision: 0.9460 - val_loss: 0.4894 - val_dice_coef: 0.5106 - val_iou: 0.3450 - val_recall: 0.1854 - val_precision: 0.6581 - lr: 0.0010\n",
            "Epoch 11/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2441 - dice_coef: 0.7559 - iou: 0.6081 - recall: 0.3092 - precision: 0.9486\n",
            "Epoch 11: val_loss improved from 0.48936 to 0.43987, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 73s 2s/step - loss: 0.2441 - dice_coef: 0.7559 - iou: 0.6081 - recall: 0.3092 - precision: 0.9486 - val_loss: 0.4399 - val_dice_coef: 0.5601 - val_iou: 0.3911 - val_recall: 0.1688 - val_precision: 0.8811 - lr: 0.0010\n",
            "Epoch 12/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2395 - dice_coef: 0.7605 - iou: 0.6140 - recall: 0.3104 - precision: 0.9517\n",
            "Epoch 12: val_loss improved from 0.43987 to 0.35674, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 72s 2s/step - loss: 0.2395 - dice_coef: 0.7605 - iou: 0.6140 - recall: 0.3104 - precision: 0.9517 - val_loss: 0.3567 - val_dice_coef: 0.6433 - val_iou: 0.4777 - val_recall: 0.2284 - val_precision: 0.8292 - lr: 0.0010\n",
            "Epoch 13/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2364 - dice_coef: 0.7636 - iou: 0.6180 - recall: 0.3110 - precision: 0.9535\n",
            "Epoch 13: val_loss improved from 0.35674 to 0.28721, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.2364 - dice_coef: 0.7636 - iou: 0.6180 - recall: 0.3110 - precision: 0.9535 - val_loss: 0.2872 - val_dice_coef: 0.7128 - val_iou: 0.5549 - val_recall: 0.2564 - val_precision: 0.9567 - lr: 0.0010\n",
            "Epoch 14/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2352 - dice_coef: 0.7648 - iou: 0.6197 - recall: 0.3117 - precision: 0.9538\n",
            "Epoch 14: val_loss did not improve from 0.28721\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2352 - dice_coef: 0.7648 - iou: 0.6197 - recall: 0.3117 - precision: 0.9538 - val_loss: 0.2914 - val_dice_coef: 0.7086 - val_iou: 0.5499 - val_recall: 0.2435 - val_precision: 0.9709 - lr: 0.0010\n",
            "Epoch 15/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2315 - dice_coef: 0.7685 - iou: 0.6245 - recall: 0.3119 - precision: 0.9563\n",
            "Epoch 15: val_loss improved from 0.28721 to 0.26012, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 73s 2s/step - loss: 0.2315 - dice_coef: 0.7685 - iou: 0.6245 - recall: 0.3119 - precision: 0.9563 - val_loss: 0.2601 - val_dice_coef: 0.7399 - val_iou: 0.5878 - val_recall: 0.2757 - val_precision: 0.9746 - lr: 0.0010\n",
            "Epoch 16/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2296 - dice_coef: 0.7704 - iou: 0.6270 - recall: 0.3124 - precision: 0.9571\n",
            "Epoch 16: val_loss did not improve from 0.26012\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2296 - dice_coef: 0.7704 - iou: 0.6270 - recall: 0.3124 - precision: 0.9571 - val_loss: 0.2686 - val_dice_coef: 0.7314 - val_iou: 0.5777 - val_recall: 0.2669 - val_precision: 0.9751 - lr: 0.0010\n",
            "Epoch 17/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2280 - dice_coef: 0.7720 - iou: 0.6291 - recall: 0.3128 - precision: 0.9576\n",
            "Epoch 17: val_loss improved from 0.26012 to 0.25878, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 72s 2s/step - loss: 0.2280 - dice_coef: 0.7720 - iou: 0.6291 - recall: 0.3128 - precision: 0.9576 - val_loss: 0.2588 - val_dice_coef: 0.7412 - val_iou: 0.5896 - val_recall: 0.2969 - val_precision: 0.9638 - lr: 0.0010\n",
            "Epoch 18/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2254 - dice_coef: 0.7746 - iou: 0.6325 - recall: 0.3129 - precision: 0.9594\n",
            "Epoch 18: val_loss improved from 0.25878 to 0.24309, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 75s 2s/step - loss: 0.2254 - dice_coef: 0.7746 - iou: 0.6325 - recall: 0.3129 - precision: 0.9594 - val_loss: 0.2431 - val_dice_coef: 0.7569 - val_iou: 0.6095 - val_recall: 0.3038 - val_precision: 0.9628 - lr: 0.0010\n",
            "Epoch 19/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2218 - dice_coef: 0.7782 - iou: 0.6373 - recall: 0.3133 - precision: 0.9614\n",
            "Epoch 19: val_loss did not improve from 0.24309\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2218 - dice_coef: 0.7782 - iou: 0.6373 - recall: 0.3133 - precision: 0.9614 - val_loss: 0.2461 - val_dice_coef: 0.7539 - val_iou: 0.6056 - val_recall: 0.3116 - val_precision: 0.9592 - lr: 0.0010\n",
            "Epoch 20/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2206 - dice_coef: 0.7794 - iou: 0.6389 - recall: 0.3130 - precision: 0.9620\n",
            "Epoch 20: val_loss did not improve from 0.24309\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.2206 - dice_coef: 0.7794 - iou: 0.6389 - recall: 0.3130 - precision: 0.9620 - val_loss: 0.2460 - val_dice_coef: 0.7540 - val_iou: 0.6058 - val_recall: 0.3089 - val_precision: 0.9623 - lr: 0.0010\n",
            "Epoch 21/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2197 - dice_coef: 0.7803 - iou: 0.6401 - recall: 0.3140 - precision: 0.9620\n",
            "Epoch 21: val_loss did not improve from 0.24309\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2197 - dice_coef: 0.7803 - iou: 0.6401 - recall: 0.3140 - precision: 0.9620 - val_loss: 0.2630 - val_dice_coef: 0.7370 - val_iou: 0.5842 - val_recall: 0.2769 - val_precision: 0.9777 - lr: 0.0010\n",
            "Epoch 22/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2197 - dice_coef: 0.7803 - iou: 0.6401 - recall: 0.3138 - precision: 0.9623\n",
            "Epoch 22: val_loss did not improve from 0.24309\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.2197 - dice_coef: 0.7803 - iou: 0.6401 - recall: 0.3138 - precision: 0.9623 - val_loss: 0.2616 - val_dice_coef: 0.7384 - val_iou: 0.5861 - val_recall: 0.2981 - val_precision: 0.9646 - lr: 0.0010\n",
            "Epoch 23/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2158 - dice_coef: 0.7842 - iou: 0.6453 - recall: 0.3145 - precision: 0.9643\n",
            "Epoch 23: val_loss improved from 0.24309 to 0.23279, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 74s 2s/step - loss: 0.2158 - dice_coef: 0.7842 - iou: 0.6453 - recall: 0.3145 - precision: 0.9643 - val_loss: 0.2328 - val_dice_coef: 0.7672 - val_iou: 0.6230 - val_recall: 0.3300 - val_precision: 0.9547 - lr: 0.0010\n",
            "Epoch 24/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2133 - dice_coef: 0.7867 - iou: 0.6487 - recall: 0.3151 - precision: 0.9655\n",
            "Epoch 24: val_loss did not improve from 0.23279\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2133 - dice_coef: 0.7867 - iou: 0.6487 - recall: 0.3151 - precision: 0.9655 - val_loss: 0.2374 - val_dice_coef: 0.7626 - val_iou: 0.6169 - val_recall: 0.3093 - val_precision: 0.9585 - lr: 0.0010\n",
            "Epoch 25/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2112 - dice_coef: 0.7888 - iou: 0.6516 - recall: 0.3145 - precision: 0.9669\n",
            "Epoch 25: val_loss did not improve from 0.23279\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2112 - dice_coef: 0.7888 - iou: 0.6516 - recall: 0.3145 - precision: 0.9669 - val_loss: 0.2382 - val_dice_coef: 0.7618 - val_iou: 0.6159 - val_recall: 0.3150 - val_precision: 0.9584 - lr: 0.0010\n",
            "Epoch 26/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2085 - dice_coef: 0.7915 - iou: 0.6553 - recall: 0.3156 - precision: 0.9679\n",
            "Epoch 26: val_loss did not improve from 0.23279\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2085 - dice_coef: 0.7915 - iou: 0.6553 - recall: 0.3156 - precision: 0.9679 - val_loss: 0.2376 - val_dice_coef: 0.7624 - val_iou: 0.6168 - val_recall: 0.3392 - val_precision: 0.9464 - lr: 0.0010\n",
            "Epoch 27/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2072 - dice_coef: 0.7928 - iou: 0.6570 - recall: 0.3161 - precision: 0.9682\n",
            "Epoch 27: val_loss did not improve from 0.23279\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.2072 - dice_coef: 0.7928 - iou: 0.6570 - recall: 0.3161 - precision: 0.9682 - val_loss: 0.2459 - val_dice_coef: 0.7541 - val_iou: 0.6058 - val_recall: 0.3202 - val_precision: 0.9531 - lr: 0.0010\n",
            "Epoch 28/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2072 - dice_coef: 0.7928 - iou: 0.6571 - recall: 0.3162 - precision: 0.9677\n",
            "Epoch 28: val_loss did not improve from 0.23279\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.2072 - dice_coef: 0.7928 - iou: 0.6571 - recall: 0.3162 - precision: 0.9677 - val_loss: 0.2540 - val_dice_coef: 0.7460 - val_iou: 0.5956 - val_recall: 0.2982 - val_precision: 0.9648 - lr: 0.0010\n",
            "Epoch 29/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.2002 - dice_coef: 0.7998 - iou: 0.6666 - recall: 0.3149 - precision: 0.9730\n",
            "Epoch 29: val_loss did not improve from 0.23279\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.2002 - dice_coef: 0.7998 - iou: 0.6666 - recall: 0.3149 - precision: 0.9730 - val_loss: 0.2353 - val_dice_coef: 0.7647 - val_iou: 0.6199 - val_recall: 0.3195 - val_precision: 0.9625 - lr: 1.0000e-04\n",
            "Epoch 30/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1951 - dice_coef: 0.8049 - iou: 0.6738 - recall: 0.3173 - precision: 0.9748\n",
            "Epoch 30: val_loss improved from 0.23279 to 0.23262, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 73s 2s/step - loss: 0.1951 - dice_coef: 0.8049 - iou: 0.6738 - recall: 0.3173 - precision: 0.9748 - val_loss: 0.2326 - val_dice_coef: 0.7674 - val_iou: 0.6235 - val_recall: 0.3204 - val_precision: 0.9637 - lr: 1.0000e-04\n",
            "Epoch 31/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1926 - dice_coef: 0.8074 - iou: 0.6773 - recall: 0.3175 - precision: 0.9761\n",
            "Epoch 31: val_loss improved from 0.23262 to 0.23203, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.1926 - dice_coef: 0.8074 - iou: 0.6773 - recall: 0.3175 - precision: 0.9761 - val_loss: 0.2320 - val_dice_coef: 0.7680 - val_iou: 0.6242 - val_recall: 0.3207 - val_precision: 0.9635 - lr: 1.0000e-04\n",
            "Epoch 32/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1906 - dice_coef: 0.8094 - iou: 0.6801 - recall: 0.3177 - precision: 0.9771\n",
            "Epoch 32: val_loss improved from 0.23203 to 0.23192, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 73s 2s/step - loss: 0.1906 - dice_coef: 0.8094 - iou: 0.6801 - recall: 0.3177 - precision: 0.9771 - val_loss: 0.2319 - val_dice_coef: 0.7681 - val_iou: 0.6243 - val_recall: 0.3207 - val_precision: 0.9634 - lr: 1.0000e-04\n",
            "Epoch 33/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1889 - dice_coef: 0.8111 - iou: 0.6825 - recall: 0.3178 - precision: 0.9779\n",
            "Epoch 33: val_loss improved from 0.23192 to 0.23187, saving model to /content/drive/MyDrive/files/lastQ1model.h5\n",
            "40/40 [==============================] - 71s 2s/step - loss: 0.1889 - dice_coef: 0.8111 - iou: 0.6825 - recall: 0.3178 - precision: 0.9779 - val_loss: 0.2319 - val_dice_coef: 0.7681 - val_iou: 0.6244 - val_recall: 0.3208 - val_precision: 0.9632 - lr: 1.0000e-04\n",
            "Epoch 34/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1874 - dice_coef: 0.8126 - iou: 0.6847 - recall: 0.3179 - precision: 0.9787\n",
            "Epoch 34: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1874 - dice_coef: 0.8126 - iou: 0.6847 - recall: 0.3179 - precision: 0.9787 - val_loss: 0.2319 - val_dice_coef: 0.7681 - val_iou: 0.6243 - val_recall: 0.3208 - val_precision: 0.9632 - lr: 1.0000e-04\n",
            "Epoch 35/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1859 - dice_coef: 0.8141 - iou: 0.6867 - recall: 0.3179 - precision: 0.9793\n",
            "Epoch 35: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1859 - dice_coef: 0.8141 - iou: 0.6867 - recall: 0.3179 - precision: 0.9793 - val_loss: 0.2321 - val_dice_coef: 0.7679 - val_iou: 0.6242 - val_recall: 0.3207 - val_precision: 0.9630 - lr: 1.0000e-04\n",
            "Epoch 36/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1846 - dice_coef: 0.8154 - iou: 0.6886 - recall: 0.3180 - precision: 0.9800\n",
            "Epoch 36: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 63s 2s/step - loss: 0.1846 - dice_coef: 0.8154 - iou: 0.6886 - recall: 0.3180 - precision: 0.9800 - val_loss: 0.2324 - val_dice_coef: 0.7676 - val_iou: 0.6238 - val_recall: 0.3203 - val_precision: 0.9630 - lr: 1.0000e-04\n",
            "Epoch 37/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1834 - dice_coef: 0.8166 - iou: 0.6903 - recall: 0.3180 - precision: 0.9806\n",
            "Epoch 37: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1834 - dice_coef: 0.8166 - iou: 0.6903 - recall: 0.3180 - precision: 0.9806 - val_loss: 0.2325 - val_dice_coef: 0.7675 - val_iou: 0.6235 - val_recall: 0.3202 - val_precision: 0.9629 - lr: 1.0000e-04\n",
            "Epoch 38/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1822 - dice_coef: 0.8178 - iou: 0.6920 - recall: 0.3180 - precision: 0.9811\n",
            "Epoch 38: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1822 - dice_coef: 0.8178 - iou: 0.6920 - recall: 0.3180 - precision: 0.9811 - val_loss: 0.2326 - val_dice_coef: 0.7674 - val_iou: 0.6234 - val_recall: 0.3205 - val_precision: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 39/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1811 - dice_coef: 0.8189 - iou: 0.6936 - recall: 0.3181 - precision: 0.9816\n",
            "Epoch 39: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1811 - dice_coef: 0.8189 - iou: 0.6936 - recall: 0.3181 - precision: 0.9816 - val_loss: 0.2330 - val_dice_coef: 0.7670 - val_iou: 0.6230 - val_recall: 0.3205 - val_precision: 0.9626 - lr: 1.0000e-04\n",
            "Epoch 40/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1800 - dice_coef: 0.8200 - iou: 0.6951 - recall: 0.3181 - precision: 0.9820\n",
            "Epoch 40: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1800 - dice_coef: 0.8200 - iou: 0.6951 - recall: 0.3181 - precision: 0.9820 - val_loss: 0.2332 - val_dice_coef: 0.7668 - val_iou: 0.6227 - val_recall: 0.3202 - val_precision: 0.9628 - lr: 1.0000e-04\n",
            "Epoch 41/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1797 - dice_coef: 0.8203 - iou: 0.6956 - recall: 0.3180 - precision: 0.9822\n",
            "Epoch 41: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1797 - dice_coef: 0.8203 - iou: 0.6956 - recall: 0.3180 - precision: 0.9822 - val_loss: 0.2339 - val_dice_coef: 0.7661 - val_iou: 0.6218 - val_recall: 0.3189 - val_precision: 0.9630 - lr: 1.0000e-04\n",
            "Epoch 42/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1802 - dice_coef: 0.8198 - iou: 0.6950 - recall: 0.3183 - precision: 0.9817\n",
            "Epoch 42: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1802 - dice_coef: 0.8198 - iou: 0.6950 - recall: 0.3183 - precision: 0.9817 - val_loss: 0.2353 - val_dice_coef: 0.7647 - val_iou: 0.6199 - val_recall: 0.3199 - val_precision: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 43/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1788 - dice_coef: 0.8212 - iou: 0.6968 - recall: 0.3182 - precision: 0.9823\n",
            "Epoch 43: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1788 - dice_coef: 0.8212 - iou: 0.6968 - recall: 0.3182 - precision: 0.9823 - val_loss: 0.2355 - val_dice_coef: 0.7645 - val_iou: 0.6196 - val_recall: 0.3203 - val_precision: 0.9608 - lr: 1.0000e-04\n",
            "Epoch 44/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1775 - dice_coef: 0.8225 - iou: 0.6987 - recall: 0.3183 - precision: 0.9829\n",
            "Epoch 44: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1775 - dice_coef: 0.8225 - iou: 0.6987 - recall: 0.3183 - precision: 0.9829 - val_loss: 0.2339 - val_dice_coef: 0.7661 - val_iou: 0.6217 - val_recall: 0.3204 - val_precision: 0.9619 - lr: 1.0000e-04\n",
            "Epoch 45/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1769 - dice_coef: 0.8231 - iou: 0.6996 - recall: 0.3183 - precision: 0.9831\n",
            "Epoch 45: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1769 - dice_coef: 0.8231 - iou: 0.6996 - recall: 0.3183 - precision: 0.9831 - val_loss: 0.2337 - val_dice_coef: 0.7663 - val_iou: 0.6219 - val_recall: 0.3217 - val_precision: 0.9613 - lr: 1.0000e-04\n",
            "Epoch 46/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1763 - dice_coef: 0.8237 - iou: 0.7005 - recall: 0.3182 - precision: 0.9834\n",
            "Epoch 46: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1763 - dice_coef: 0.8237 - iou: 0.7005 - recall: 0.3182 - precision: 0.9834 - val_loss: 0.2344 - val_dice_coef: 0.7656 - val_iou: 0.6211 - val_recall: 0.3211 - val_precision: 0.9614 - lr: 1.0000e-04\n",
            "Epoch 47/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1760 - dice_coef: 0.8240 - iou: 0.7009 - recall: 0.3186 - precision: 0.9834\n",
            "Epoch 47: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1760 - dice_coef: 0.8240 - iou: 0.7009 - recall: 0.3186 - precision: 0.9834 - val_loss: 0.2355 - val_dice_coef: 0.7645 - val_iou: 0.6196 - val_recall: 0.3175 - val_precision: 0.9629 - lr: 1.0000e-04\n",
            "Epoch 48/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1764 - dice_coef: 0.8236 - iou: 0.7003 - recall: 0.3189 - precision: 0.9831\n",
            "Epoch 48: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1764 - dice_coef: 0.8236 - iou: 0.7003 - recall: 0.3189 - precision: 0.9831 - val_loss: 0.2399 - val_dice_coef: 0.7601 - val_iou: 0.6139 - val_recall: 0.3128 - val_precision: 0.9631 - lr: 1.0000e-04\n",
            "Epoch 49/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1768 - dice_coef: 0.8232 - iou: 0.6998 - recall: 0.3191 - precision: 0.9828\n",
            "Epoch 49: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1768 - dice_coef: 0.8232 - iou: 0.6998 - recall: 0.3191 - precision: 0.9828 - val_loss: 0.2372 - val_dice_coef: 0.7628 - val_iou: 0.6173 - val_recall: 0.3136 - val_precision: 0.9637 - lr: 1.0000e-04\n",
            "Epoch 50/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1767 - dice_coef: 0.8233 - iou: 0.6999 - recall: 0.3185 - precision: 0.9830\n",
            "Epoch 50: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 63s 2s/step - loss: 0.1767 - dice_coef: 0.8233 - iou: 0.6999 - recall: 0.3185 - precision: 0.9830 - val_loss: 0.2352 - val_dice_coef: 0.7648 - val_iou: 0.6200 - val_recall: 0.3157 - val_precision: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 51/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1756 - dice_coef: 0.8244 - iou: 0.7015 - recall: 0.3187 - precision: 0.9835\n",
            "Epoch 51: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1756 - dice_coef: 0.8244 - iou: 0.7015 - recall: 0.3187 - precision: 0.9835 - val_loss: 0.2389 - val_dice_coef: 0.7611 - val_iou: 0.6152 - val_recall: 0.3130 - val_precision: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 52/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1734 - dice_coef: 0.8266 - iou: 0.7046 - recall: 0.3192 - precision: 0.9843\n",
            "Epoch 52: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1734 - dice_coef: 0.8266 - iou: 0.7046 - recall: 0.3192 - precision: 0.9843 - val_loss: 0.2426 - val_dice_coef: 0.7574 - val_iou: 0.6103 - val_recall: 0.3098 - val_precision: 0.9634 - lr: 1.0000e-04\n",
            "Epoch 53/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1725 - dice_coef: 0.8275 - iou: 0.7061 - recall: 0.3189 - precision: 0.9848\n",
            "Epoch 53: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 62s 2s/step - loss: 0.1725 - dice_coef: 0.8275 - iou: 0.7061 - recall: 0.3189 - precision: 0.9848 - val_loss: 0.2388 - val_dice_coef: 0.7612 - val_iou: 0.6153 - val_recall: 0.3127 - val_precision: 0.9636 - lr: 1.0000e-04\n",
            "Epoch 54/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1716 - dice_coef: 0.8284 - iou: 0.7073 - recall: 0.3189 - precision: 0.9852\n",
            "Epoch 54: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 63s 2s/step - loss: 0.1716 - dice_coef: 0.8284 - iou: 0.7073 - recall: 0.3189 - precision: 0.9852 - val_loss: 0.2372 - val_dice_coef: 0.7628 - val_iou: 0.6173 - val_recall: 0.3126 - val_precision: 0.9639 - lr: 1.0000e-04\n",
            "Epoch 55/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1707 - dice_coef: 0.8293 - iou: 0.7086 - recall: 0.3188 - precision: 0.9855\n",
            "Epoch 55: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1707 - dice_coef: 0.8293 - iou: 0.7086 - recall: 0.3188 - precision: 0.9855 - val_loss: 0.2374 - val_dice_coef: 0.7626 - val_iou: 0.6172 - val_recall: 0.3136 - val_precision: 0.9640 - lr: 1.0000e-04\n",
            "Epoch 56/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1703 - dice_coef: 0.8297 - iou: 0.7091 - recall: 0.3187 - precision: 0.9858\n",
            "Epoch 56: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1703 - dice_coef: 0.8297 - iou: 0.7091 - recall: 0.3187 - precision: 0.9858 - val_loss: 0.2388 - val_dice_coef: 0.7612 - val_iou: 0.6153 - val_recall: 0.3160 - val_precision: 0.9618 - lr: 1.0000e-04\n",
            "Epoch 57/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1700 - dice_coef: 0.8300 - iou: 0.7096 - recall: 0.3186 - precision: 0.9860\n",
            "Epoch 57: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1700 - dice_coef: 0.8300 - iou: 0.7096 - recall: 0.3186 - precision: 0.9860 - val_loss: 0.2405 - val_dice_coef: 0.7595 - val_iou: 0.6130 - val_recall: 0.3187 - val_precision: 0.9579 - lr: 1.0000e-04\n",
            "Epoch 58/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1701 - dice_coef: 0.8299 - iou: 0.7095 - recall: 0.3183 - precision: 0.9859\n",
            "Epoch 58: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1701 - dice_coef: 0.8299 - iou: 0.7095 - recall: 0.3183 - precision: 0.9859 - val_loss: 0.2384 - val_dice_coef: 0.7616 - val_iou: 0.6158 - val_recall: 0.3202 - val_precision: 0.9585 - lr: 1.0000e-04\n",
            "Epoch 59/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1702 - dice_coef: 0.8298 - iou: 0.7093 - recall: 0.3187 - precision: 0.9857\n",
            "Epoch 59: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1702 - dice_coef: 0.8298 - iou: 0.7093 - recall: 0.3187 - precision: 0.9857 - val_loss: 0.2375 - val_dice_coef: 0.7625 - val_iou: 0.6170 - val_recall: 0.3191 - val_precision: 0.9608 - lr: 1.0000e-04\n",
            "Epoch 60/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1691 - dice_coef: 0.8309 - iou: 0.7110 - recall: 0.3198 - precision: 0.9859\n",
            "Epoch 60: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1691 - dice_coef: 0.8309 - iou: 0.7110 - recall: 0.3198 - precision: 0.9859 - val_loss: 0.2415 - val_dice_coef: 0.7585 - val_iou: 0.6118 - val_recall: 0.3115 - val_precision: 0.9627 - lr: 1.0000e-04\n",
            "Epoch 61/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1674 - dice_coef: 0.8326 - iou: 0.7134 - recall: 0.3192 - precision: 0.9868\n",
            "Epoch 61: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1674 - dice_coef: 0.8326 - iou: 0.7134 - recall: 0.3192 - precision: 0.9868 - val_loss: 0.2415 - val_dice_coef: 0.7585 - val_iou: 0.6117 - val_recall: 0.3122 - val_precision: 0.9606 - lr: 1.0000e-04\n",
            "Epoch 62/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1671 - dice_coef: 0.8329 - iou: 0.7138 - recall: 0.3189 - precision: 0.9870\n",
            "Epoch 62: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1671 - dice_coef: 0.8329 - iou: 0.7138 - recall: 0.3189 - precision: 0.9870 - val_loss: 0.2412 - val_dice_coef: 0.7588 - val_iou: 0.6122 - val_recall: 0.3148 - val_precision: 0.9594 - lr: 1.0000e-04\n",
            "Epoch 63/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1675 - dice_coef: 0.8325 - iou: 0.7133 - recall: 0.3192 - precision: 0.9867\n",
            "Epoch 63: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1675 - dice_coef: 0.8325 - iou: 0.7133 - recall: 0.3192 - precision: 0.9867 - val_loss: 0.2419 - val_dice_coef: 0.7581 - val_iou: 0.6112 - val_recall: 0.3128 - val_precision: 0.9598 - lr: 1.0000e-04\n",
            "Epoch 64/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1677 - dice_coef: 0.8323 - iou: 0.7130 - recall: 0.3193 - precision: 0.9866\n",
            "Epoch 64: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1677 - dice_coef: 0.8323 - iou: 0.7130 - recall: 0.3193 - precision: 0.9866 - val_loss: 0.2407 - val_dice_coef: 0.7593 - val_iou: 0.6128 - val_recall: 0.3121 - val_precision: 0.9606 - lr: 1.0000e-04\n",
            "Epoch 65/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1670 - dice_coef: 0.8330 - iou: 0.7140 - recall: 0.3192 - precision: 0.9870\n",
            "Epoch 65: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1670 - dice_coef: 0.8330 - iou: 0.7140 - recall: 0.3192 - precision: 0.9870 - val_loss: 0.2425 - val_dice_coef: 0.7575 - val_iou: 0.6104 - val_recall: 0.3100 - val_precision: 0.9605 - lr: 1.0000e-04\n",
            "Epoch 66/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1656 - dice_coef: 0.8344 - iou: 0.7161 - recall: 0.3194 - precision: 0.9875\n",
            "Epoch 66: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1656 - dice_coef: 0.8344 - iou: 0.7161 - recall: 0.3194 - precision: 0.9875 - val_loss: 0.2440 - val_dice_coef: 0.7560 - val_iou: 0.6085 - val_recall: 0.3081 - val_precision: 0.9612 - lr: 1.0000e-04\n",
            "Epoch 67/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1650 - dice_coef: 0.8350 - iou: 0.7170 - recall: 0.3195 - precision: 0.9877\n",
            "Epoch 67: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1650 - dice_coef: 0.8350 - iou: 0.7170 - recall: 0.3195 - precision: 0.9877 - val_loss: 0.2459 - val_dice_coef: 0.7541 - val_iou: 0.6061 - val_recall: 0.3054 - val_precision: 0.9616 - lr: 1.0000e-04\n",
            "Epoch 68/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1645 - dice_coef: 0.8355 - iou: 0.7177 - recall: 0.3195 - precision: 0.9879\n",
            "Epoch 68: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1645 - dice_coef: 0.8355 - iou: 0.7177 - recall: 0.3195 - precision: 0.9879 - val_loss: 0.2440 - val_dice_coef: 0.7560 - val_iou: 0.6084 - val_recall: 0.3055 - val_precision: 0.9619 - lr: 1.0000e-04\n",
            "Epoch 69/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1637 - dice_coef: 0.8363 - iou: 0.7188 - recall: 0.3198 - precision: 0.9881\n",
            "Epoch 69: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1637 - dice_coef: 0.8363 - iou: 0.7188 - recall: 0.3198 - precision: 0.9881 - val_loss: 0.2431 - val_dice_coef: 0.7569 - val_iou: 0.6096 - val_recall: 0.3062 - val_precision: 0.9628 - lr: 1.0000e-04\n",
            "Epoch 70/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1631 - dice_coef: 0.8369 - iou: 0.7198 - recall: 0.3198 - precision: 0.9883\n",
            "Epoch 70: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1631 - dice_coef: 0.8369 - iou: 0.7198 - recall: 0.3198 - precision: 0.9883 - val_loss: 0.2422 - val_dice_coef: 0.7578 - val_iou: 0.6108 - val_recall: 0.3057 - val_precision: 0.9637 - lr: 1.0000e-04\n",
            "Epoch 71/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1630 - dice_coef: 0.8370 - iou: 0.7200 - recall: 0.3194 - precision: 0.9885\n",
            "Epoch 71: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1630 - dice_coef: 0.8370 - iou: 0.7200 - recall: 0.3194 - precision: 0.9885 - val_loss: 0.2420 - val_dice_coef: 0.7580 - val_iou: 0.6111 - val_recall: 0.3079 - val_precision: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 72/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1623 - dice_coef: 0.8377 - iou: 0.7209 - recall: 0.3189 - precision: 0.9889\n",
            "Epoch 72: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1623 - dice_coef: 0.8377 - iou: 0.7209 - recall: 0.3189 - precision: 0.9889 - val_loss: 0.2398 - val_dice_coef: 0.7602 - val_iou: 0.6139 - val_recall: 0.3143 - val_precision: 0.9583 - lr: 1.0000e-04\n",
            "Epoch 73/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1624 - dice_coef: 0.8376 - iou: 0.7208 - recall: 0.3191 - precision: 0.9887\n",
            "Epoch 73: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1624 - dice_coef: 0.8376 - iou: 0.7208 - recall: 0.3191 - precision: 0.9887 - val_loss: 0.2400 - val_dice_coef: 0.7600 - val_iou: 0.6136 - val_recall: 0.3134 - val_precision: 0.9607 - lr: 1.0000e-04\n",
            "Epoch 74/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1621 - dice_coef: 0.8379 - iou: 0.7212 - recall: 0.3195 - precision: 0.9887\n",
            "Epoch 74: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1621 - dice_coef: 0.8379 - iou: 0.7212 - recall: 0.3195 - precision: 0.9887 - val_loss: 0.2417 - val_dice_coef: 0.7583 - val_iou: 0.6115 - val_recall: 0.3119 - val_precision: 0.9599 - lr: 1.0000e-04\n",
            "Epoch 75/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1613 - dice_coef: 0.8387 - iou: 0.7224 - recall: 0.3192 - precision: 0.9891\n",
            "Epoch 75: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1613 - dice_coef: 0.8387 - iou: 0.7224 - recall: 0.3192 - precision: 0.9891 - val_loss: 0.2402 - val_dice_coef: 0.7598 - val_iou: 0.6134 - val_recall: 0.3142 - val_precision: 0.9573 - lr: 1.0000e-04\n",
            "Epoch 76/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3191 - precision: 0.9893\n",
            "Epoch 76: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3191 - precision: 0.9893 - val_loss: 0.2373 - val_dice_coef: 0.7627 - val_iou: 0.6172 - val_recall: 0.3153 - val_precision: 0.9602 - lr: 1.0000e-04\n",
            "Epoch 77/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3193 - precision: 0.9892\n",
            "Epoch 77: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3193 - precision: 0.9892 - val_loss: 0.2383 - val_dice_coef: 0.7617 - val_iou: 0.6159 - val_recall: 0.3140 - val_precision: 0.9619 - lr: 1.0000e-04\n",
            "Epoch 78/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3199 - precision: 0.9891\n",
            "Epoch 78: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1607 - dice_coef: 0.8393 - iou: 0.7233 - recall: 0.3199 - precision: 0.9891 - val_loss: 0.2420 - val_dice_coef: 0.7580 - val_iou: 0.6110 - val_recall: 0.3070 - val_precision: 0.9640 - lr: 1.0000e-04\n",
            "Epoch 79/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1604 - dice_coef: 0.8396 - iou: 0.7238 - recall: 0.3198 - precision: 0.9892\n",
            "Epoch 79: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1604 - dice_coef: 0.8396 - iou: 0.7238 - recall: 0.3198 - precision: 0.9892 - val_loss: 0.2424 - val_dice_coef: 0.7576 - val_iou: 0.6105 - val_recall: 0.3071 - val_precision: 0.9633 - lr: 1.0000e-04\n",
            "Epoch 80/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1596 - dice_coef: 0.8404 - iou: 0.7249 - recall: 0.3196 - precision: 0.9895\n",
            "Epoch 80: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1596 - dice_coef: 0.8404 - iou: 0.7249 - recall: 0.3196 - precision: 0.9895 - val_loss: 0.2408 - val_dice_coef: 0.7592 - val_iou: 0.6126 - val_recall: 0.3105 - val_precision: 0.9622 - lr: 1.0000e-04\n",
            "Epoch 81/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1587 - dice_coef: 0.8413 - iou: 0.7263 - recall: 0.3200 - precision: 0.9898\n",
            "Epoch 81: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1587 - dice_coef: 0.8413 - iou: 0.7263 - recall: 0.3200 - precision: 0.9898 - val_loss: 0.2412 - val_dice_coef: 0.7588 - val_iou: 0.6121 - val_recall: 0.3082 - val_precision: 0.9636 - lr: 1.0000e-04\n",
            "Epoch 82/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1585 - dice_coef: 0.8415 - iou: 0.7266 - recall: 0.3199 - precision: 0.9900\n",
            "Epoch 82: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1585 - dice_coef: 0.8415 - iou: 0.7266 - recall: 0.3199 - precision: 0.9900 - val_loss: 0.2428 - val_dice_coef: 0.7572 - val_iou: 0.6100 - val_recall: 0.3044 - val_precision: 0.9664 - lr: 1.0000e-04\n",
            "Epoch 83/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1582 - dice_coef: 0.8418 - iou: 0.7271 - recall: 0.3199 - precision: 0.9901\n",
            "Epoch 83: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1582 - dice_coef: 0.8418 - iou: 0.7271 - recall: 0.3199 - precision: 0.9901 - val_loss: 0.2422 - val_dice_coef: 0.7578 - val_iou: 0.6108 - val_recall: 0.3059 - val_precision: 0.9661 - lr: 1.0000e-04\n",
            "Epoch 84/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1584 - dice_coef: 0.8416 - iou: 0.7267 - recall: 0.3198 - precision: 0.9899\n",
            "Epoch 84: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1584 - dice_coef: 0.8416 - iou: 0.7267 - recall: 0.3198 - precision: 0.9899 - val_loss: 0.2394 - val_dice_coef: 0.7606 - val_iou: 0.6144 - val_recall: 0.3109 - val_precision: 0.9640 - lr: 1.0000e-04\n",
            "Epoch 85/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1590 - dice_coef: 0.8410 - iou: 0.7258 - recall: 0.3198 - precision: 0.9897\n",
            "Epoch 85: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1590 - dice_coef: 0.8410 - iou: 0.7258 - recall: 0.3198 - precision: 0.9897 - val_loss: 0.2400 - val_dice_coef: 0.7600 - val_iou: 0.6136 - val_recall: 0.3104 - val_precision: 0.9639 - lr: 1.0000e-04\n",
            "Epoch 86/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1588 - dice_coef: 0.8412 - iou: 0.7262 - recall: 0.3197 - precision: 0.9899\n",
            "Epoch 86: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1588 - dice_coef: 0.8412 - iou: 0.7262 - recall: 0.3197 - precision: 0.9899 - val_loss: 0.2421 - val_dice_coef: 0.7579 - val_iou: 0.6109 - val_recall: 0.3121 - val_precision: 0.9622 - lr: 1.0000e-04\n",
            "Epoch 87/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1584 - dice_coef: 0.8416 - iou: 0.7267 - recall: 0.3198 - precision: 0.9900\n",
            "Epoch 87: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1584 - dice_coef: 0.8416 - iou: 0.7267 - recall: 0.3198 - precision: 0.9900 - val_loss: 0.2405 - val_dice_coef: 0.7595 - val_iou: 0.6130 - val_recall: 0.3151 - val_precision: 0.9616 - lr: 1.0000e-04\n",
            "Epoch 88/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1578 - dice_coef: 0.8422 - iou: 0.7277 - recall: 0.3195 - precision: 0.9903\n",
            "Epoch 88: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1578 - dice_coef: 0.8422 - iou: 0.7277 - recall: 0.3195 - precision: 0.9903 - val_loss: 0.2387 - val_dice_coef: 0.7613 - val_iou: 0.6153 - val_recall: 0.3167 - val_precision: 0.9603 - lr: 1.0000e-04\n",
            "Epoch 89/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3194 - precision: 0.9904\n",
            "Epoch 89: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3194 - precision: 0.9904 - val_loss: 0.2388 - val_dice_coef: 0.7612 - val_iou: 0.6152 - val_recall: 0.3163 - val_precision: 0.9600 - lr: 1.0000e-04\n",
            "Epoch 90/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1569 - dice_coef: 0.8431 - iou: 0.7290 - recall: 0.3199 - precision: 0.9904\n",
            "Epoch 90: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1569 - dice_coef: 0.8431 - iou: 0.7290 - recall: 0.3199 - precision: 0.9904 - val_loss: 0.2421 - val_dice_coef: 0.7579 - val_iou: 0.6109 - val_recall: 0.3120 - val_precision: 0.9602 - lr: 1.0000e-04\n",
            "Epoch 91/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3206 - precision: 0.9901\n",
            "Epoch 91: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3206 - precision: 0.9901 - val_loss: 0.2452 - val_dice_coef: 0.7548 - val_iou: 0.6069 - val_recall: 0.3084 - val_precision: 0.9595 - lr: 1.0000e-04\n",
            "Epoch 92/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3202 - precision: 0.9902\n",
            "Epoch 92: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1572 - dice_coef: 0.8428 - iou: 0.7285 - recall: 0.3202 - precision: 0.9902 - val_loss: 0.2475 - val_dice_coef: 0.7525 - val_iou: 0.6039 - val_recall: 0.3032 - val_precision: 0.9599 - lr: 1.0000e-04\n",
            "Epoch 93/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1566 - dice_coef: 0.8434 - iou: 0.7294 - recall: 0.3204 - precision: 0.9903\n",
            "Epoch 93: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1566 - dice_coef: 0.8434 - iou: 0.7294 - recall: 0.3204 - precision: 0.9903 - val_loss: 0.2455 - val_dice_coef: 0.7545 - val_iou: 0.6065 - val_recall: 0.3060 - val_precision: 0.9591 - lr: 1.0000e-04\n",
            "Epoch 94/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1561 - dice_coef: 0.8439 - iou: 0.7302 - recall: 0.3203 - precision: 0.9905\n",
            "Epoch 94: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1561 - dice_coef: 0.8439 - iou: 0.7302 - recall: 0.3203 - precision: 0.9905 - val_loss: 0.2418 - val_dice_coef: 0.7582 - val_iou: 0.6112 - val_recall: 0.3138 - val_precision: 0.9561 - lr: 1.0000e-04\n",
            "Epoch 95/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1558 - dice_coef: 0.8442 - iou: 0.7306 - recall: 0.3199 - precision: 0.9908\n",
            "Epoch 95: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1558 - dice_coef: 0.8442 - iou: 0.7306 - recall: 0.3199 - precision: 0.9908 - val_loss: 0.2422 - val_dice_coef: 0.7578 - val_iou: 0.6107 - val_recall: 0.3151 - val_precision: 0.9553 - lr: 1.0000e-04\n",
            "Epoch 96/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1554 - dice_coef: 0.8446 - iou: 0.7312 - recall: 0.3196 - precision: 0.9911\n",
            "Epoch 96: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1554 - dice_coef: 0.8446 - iou: 0.7312 - recall: 0.3196 - precision: 0.9911 - val_loss: 0.2423 - val_dice_coef: 0.7577 - val_iou: 0.6107 - val_recall: 0.3130 - val_precision: 0.9570 - lr: 1.0000e-04\n",
            "Epoch 97/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1553 - dice_coef: 0.8447 - iou: 0.7314 - recall: 0.3198 - precision: 0.9911\n",
            "Epoch 97: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1553 - dice_coef: 0.8447 - iou: 0.7314 - recall: 0.3198 - precision: 0.9911 - val_loss: 0.2442 - val_dice_coef: 0.7558 - val_iou: 0.6083 - val_recall: 0.3052 - val_precision: 0.9626 - lr: 1.0000e-04\n",
            "Epoch 98/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1553 - dice_coef: 0.8447 - iou: 0.7313 - recall: 0.3207 - precision: 0.9908\n",
            "Epoch 98: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1553 - dice_coef: 0.8447 - iou: 0.7313 - recall: 0.3207 - precision: 0.9908 - val_loss: 0.2493 - val_dice_coef: 0.7507 - val_iou: 0.6016 - val_recall: 0.2972 - val_precision: 0.9666 - lr: 1.0000e-04\n",
            "Epoch 99/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1552 - dice_coef: 0.8448 - iou: 0.7315 - recall: 0.3208 - precision: 0.9907\n",
            "Epoch 99: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1552 - dice_coef: 0.8448 - iou: 0.7315 - recall: 0.3208 - precision: 0.9907 - val_loss: 0.2464 - val_dice_coef: 0.7536 - val_iou: 0.6054 - val_recall: 0.3053 - val_precision: 0.9619 - lr: 1.0000e-04\n",
            "Epoch 100/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1550 - dice_coef: 0.8450 - iou: 0.7318 - recall: 0.3204 - precision: 0.9910\n",
            "Epoch 100: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1550 - dice_coef: 0.8450 - iou: 0.7318 - recall: 0.3204 - precision: 0.9910 - val_loss: 0.2451 - val_dice_coef: 0.7549 - val_iou: 0.6070 - val_recall: 0.3079 - val_precision: 0.9594 - lr: 1.0000e-04\n",
            "Epoch 101/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1546 - dice_coef: 0.8454 - iou: 0.7324 - recall: 0.3204 - precision: 0.9911\n",
            "Epoch 101: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1546 - dice_coef: 0.8454 - iou: 0.7324 - recall: 0.3204 - precision: 0.9911 - val_loss: 0.2452 - val_dice_coef: 0.7548 - val_iou: 0.6069 - val_recall: 0.3082 - val_precision: 0.9600 - lr: 1.0000e-04\n",
            "Epoch 102/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1540 - dice_coef: 0.8460 - iou: 0.7334 - recall: 0.3206 - precision: 0.9913\n",
            "Epoch 102: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1540 - dice_coef: 0.8460 - iou: 0.7334 - recall: 0.3206 - precision: 0.9913 - val_loss: 0.2497 - val_dice_coef: 0.7503 - val_iou: 0.6011 - val_recall: 0.3025 - val_precision: 0.9622 - lr: 1.0000e-04\n",
            "Epoch 103/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1539 - dice_coef: 0.8461 - iou: 0.7334 - recall: 0.3207 - precision: 0.9913\n",
            "Epoch 103: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1539 - dice_coef: 0.8461 - iou: 0.7334 - recall: 0.3207 - precision: 0.9913 - val_loss: 0.2529 - val_dice_coef: 0.7471 - val_iou: 0.5971 - val_recall: 0.2961 - val_precision: 0.9646 - lr: 1.0000e-04\n",
            "Epoch 104/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1537 - dice_coef: 0.8463 - iou: 0.7337 - recall: 0.3208 - precision: 0.9913\n",
            "Epoch 104: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1537 - dice_coef: 0.8463 - iou: 0.7337 - recall: 0.3208 - precision: 0.9913 - val_loss: 0.2558 - val_dice_coef: 0.7442 - val_iou: 0.5934 - val_recall: 0.2912 - val_precision: 0.9652 - lr: 1.0000e-04\n",
            "Epoch 105/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1534 - dice_coef: 0.8466 - iou: 0.7343 - recall: 0.3209 - precision: 0.9914\n",
            "Epoch 105: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1534 - dice_coef: 0.8466 - iou: 0.7343 - recall: 0.3209 - precision: 0.9914 - val_loss: 0.2545 - val_dice_coef: 0.7455 - val_iou: 0.5950 - val_recall: 0.2949 - val_precision: 0.9638 - lr: 1.0000e-04\n",
            "Epoch 106/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1531 - dice_coef: 0.8469 - iou: 0.7347 - recall: 0.3205 - precision: 0.9917\n",
            "Epoch 106: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1531 - dice_coef: 0.8469 - iou: 0.7347 - recall: 0.3205 - precision: 0.9917 - val_loss: 0.2519 - val_dice_coef: 0.7481 - val_iou: 0.5984 - val_recall: 0.3014 - val_precision: 0.9620 - lr: 1.0000e-04\n",
            "Epoch 107/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3198 - precision: 0.9920\n",
            "Epoch 107: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3198 - precision: 0.9920 - val_loss: 0.2491 - val_dice_coef: 0.7509 - val_iou: 0.6020 - val_recall: 0.3070 - val_precision: 0.9608 - lr: 1.0000e-04\n",
            "Epoch 108/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3198 - precision: 0.9919\n",
            "Epoch 108: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3198 - precision: 0.9919 - val_loss: 0.2489 - val_dice_coef: 0.7511 - val_iou: 0.6022 - val_recall: 0.3045 - val_precision: 0.9631 - lr: 1.0000e-04\n",
            "Epoch 109/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3207 - precision: 0.9916\n",
            "Epoch 109: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1528 - dice_coef: 0.8472 - iou: 0.7351 - recall: 0.3207 - precision: 0.9916 - val_loss: 0.2500 - val_dice_coef: 0.7500 - val_iou: 0.6008 - val_recall: 0.3031 - val_precision: 0.9628 - lr: 1.0000e-04\n",
            "Epoch 110/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1525 - dice_coef: 0.8475 - iou: 0.7355 - recall: 0.3213 - precision: 0.9916\n",
            "Epoch 110: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1525 - dice_coef: 0.8475 - iou: 0.7355 - recall: 0.3213 - precision: 0.9916 - val_loss: 0.2496 - val_dice_coef: 0.7504 - val_iou: 0.6013 - val_recall: 0.3032 - val_precision: 0.9621 - lr: 1.0000e-04\n",
            "Epoch 111/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1519 - dice_coef: 0.8481 - iou: 0.7364 - recall: 0.3210 - precision: 0.9919\n",
            "Epoch 111: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1519 - dice_coef: 0.8481 - iou: 0.7364 - recall: 0.3210 - precision: 0.9919 - val_loss: 0.2456 - val_dice_coef: 0.7544 - val_iou: 0.6063 - val_recall: 0.3078 - val_precision: 0.9607 - lr: 1.0000e-04\n",
            "Epoch 112/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1514 - dice_coef: 0.8486 - iou: 0.7372 - recall: 0.3205 - precision: 0.9922\n",
            "Epoch 112: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1514 - dice_coef: 0.8486 - iou: 0.7372 - recall: 0.3205 - precision: 0.9922 - val_loss: 0.2451 - val_dice_coef: 0.7549 - val_iou: 0.6070 - val_recall: 0.3064 - val_precision: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 113/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1515 - dice_coef: 0.8485 - iou: 0.7370 - recall: 0.3208 - precision: 0.9920\n",
            "Epoch 113: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1515 - dice_coef: 0.8485 - iou: 0.7370 - recall: 0.3208 - precision: 0.9920 - val_loss: 0.2471 - val_dice_coef: 0.7529 - val_iou: 0.6044 - val_recall: 0.2987 - val_precision: 0.9648 - lr: 1.0000e-04\n",
            "Epoch 114/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1513 - dice_coef: 0.8487 - iou: 0.7373 - recall: 0.3215 - precision: 0.9920\n",
            "Epoch 114: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1513 - dice_coef: 0.8487 - iou: 0.7373 - recall: 0.3215 - precision: 0.9920 - val_loss: 0.2530 - val_dice_coef: 0.7470 - val_iou: 0.5969 - val_recall: 0.2903 - val_precision: 0.9674 - lr: 1.0000e-04\n",
            "Epoch 115/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1510 - dice_coef: 0.8490 - iou: 0.7379 - recall: 0.3213 - precision: 0.9922\n",
            "Epoch 115: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1510 - dice_coef: 0.8490 - iou: 0.7379 - recall: 0.3213 - precision: 0.9922 - val_loss: 0.2508 - val_dice_coef: 0.7492 - val_iou: 0.5997 - val_recall: 0.2960 - val_precision: 0.9652 - lr: 1.0000e-04\n",
            "Epoch 116/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1506 - dice_coef: 0.8494 - iou: 0.7385 - recall: 0.3202 - precision: 0.9926\n",
            "Epoch 116: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1506 - dice_coef: 0.8494 - iou: 0.7385 - recall: 0.3202 - precision: 0.9926 - val_loss: 0.2460 - val_dice_coef: 0.7540 - val_iou: 0.6059 - val_recall: 0.3054 - val_precision: 0.9622 - lr: 1.0000e-04\n",
            "Epoch 117/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1499 - dice_coef: 0.8501 - iou: 0.7395 - recall: 0.3198 - precision: 0.9927\n",
            "Epoch 117: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1499 - dice_coef: 0.8501 - iou: 0.7395 - recall: 0.3198 - precision: 0.9927 - val_loss: 0.2446 - val_dice_coef: 0.7554 - val_iou: 0.6076 - val_recall: 0.3101 - val_precision: 0.9612 - lr: 1.0000e-04\n",
            "Epoch 118/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1497 - dice_coef: 0.8503 - iou: 0.7398 - recall: 0.3205 - precision: 0.9926\n",
            "Epoch 118: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1497 - dice_coef: 0.8503 - iou: 0.7398 - recall: 0.3205 - precision: 0.9926 - val_loss: 0.2485 - val_dice_coef: 0.7515 - val_iou: 0.6027 - val_recall: 0.3085 - val_precision: 0.9614 - lr: 1.0000e-04\n",
            "Epoch 119/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1494 - dice_coef: 0.8506 - iou: 0.7403 - recall: 0.3212 - precision: 0.9926\n",
            "Epoch 119: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1494 - dice_coef: 0.8506 - iou: 0.7403 - recall: 0.3212 - precision: 0.9926 - val_loss: 0.2514 - val_dice_coef: 0.7486 - val_iou: 0.5990 - val_recall: 0.3045 - val_precision: 0.9621 - lr: 1.0000e-04\n",
            "Epoch 120/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1497 - dice_coef: 0.8503 - iou: 0.7398 - recall: 0.3210 - precision: 0.9925\n",
            "Epoch 120: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1497 - dice_coef: 0.8503 - iou: 0.7398 - recall: 0.3210 - precision: 0.9925 - val_loss: 0.2477 - val_dice_coef: 0.7523 - val_iou: 0.6037 - val_recall: 0.3070 - val_precision: 0.9621 - lr: 1.0000e-04\n",
            "Epoch 121/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1498 - dice_coef: 0.8502 - iou: 0.7396 - recall: 0.3211 - precision: 0.9924\n",
            "Epoch 121: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1498 - dice_coef: 0.8502 - iou: 0.7396 - recall: 0.3211 - precision: 0.9924 - val_loss: 0.2471 - val_dice_coef: 0.7529 - val_iou: 0.6046 - val_recall: 0.3061 - val_precision: 0.9632 - lr: 1.0000e-04\n",
            "Epoch 122/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1498 - dice_coef: 0.8502 - iou: 0.7396 - recall: 0.3214 - precision: 0.9923\n",
            "Epoch 122: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1498 - dice_coef: 0.8502 - iou: 0.7396 - recall: 0.3214 - precision: 0.9923 - val_loss: 0.2489 - val_dice_coef: 0.7511 - val_iou: 0.6022 - val_recall: 0.3011 - val_precision: 0.9651 - lr: 1.0000e-04\n",
            "Epoch 123/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1496 - dice_coef: 0.8504 - iou: 0.7399 - recall: 0.3213 - precision: 0.9925\n",
            "Epoch 123: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1496 - dice_coef: 0.8504 - iou: 0.7399 - recall: 0.3213 - precision: 0.9925 - val_loss: 0.2474 - val_dice_coef: 0.7526 - val_iou: 0.6041 - val_recall: 0.3055 - val_precision: 0.9610 - lr: 1.0000e-04\n",
            "Epoch 124/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1490 - dice_coef: 0.8510 - iou: 0.7408 - recall: 0.3206 - precision: 0.9929\n",
            "Epoch 124: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1490 - dice_coef: 0.8510 - iou: 0.7408 - recall: 0.3206 - precision: 0.9929 - val_loss: 0.2441 - val_dice_coef: 0.7559 - val_iou: 0.6084 - val_recall: 0.3142 - val_precision: 0.9546 - lr: 1.0000e-04\n",
            "Epoch 125/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1486 - dice_coef: 0.8514 - iou: 0.7414 - recall: 0.3204 - precision: 0.9931\n",
            "Epoch 125: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1486 - dice_coef: 0.8514 - iou: 0.7414 - recall: 0.3204 - precision: 0.9931 - val_loss: 0.2429 - val_dice_coef: 0.7571 - val_iou: 0.6098 - val_recall: 0.3180 - val_precision: 0.9518 - lr: 1.0000e-04\n",
            "Epoch 126/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1485 - dice_coef: 0.8515 - iou: 0.7416 - recall: 0.3209 - precision: 0.9930\n",
            "Epoch 126: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1485 - dice_coef: 0.8515 - iou: 0.7416 - recall: 0.3209 - precision: 0.9930 - val_loss: 0.2457 - val_dice_coef: 0.7543 - val_iou: 0.6062 - val_recall: 0.3151 - val_precision: 0.9510 - lr: 1.0000e-04\n",
            "Epoch 127/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1481 - dice_coef: 0.8519 - iou: 0.7423 - recall: 0.3211 - precision: 0.9930\n",
            "Epoch 127: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1481 - dice_coef: 0.8519 - iou: 0.7423 - recall: 0.3211 - precision: 0.9930 - val_loss: 0.2482 - val_dice_coef: 0.7518 - val_iou: 0.6030 - val_recall: 0.3097 - val_precision: 0.9521 - lr: 1.0000e-04\n",
            "Epoch 128/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1475 - dice_coef: 0.8525 - iou: 0.7430 - recall: 0.3213 - precision: 0.9932\n",
            "Epoch 128: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1475 - dice_coef: 0.8525 - iou: 0.7430 - recall: 0.3213 - precision: 0.9932 - val_loss: 0.2498 - val_dice_coef: 0.7502 - val_iou: 0.6009 - val_recall: 0.3048 - val_precision: 0.9536 - lr: 1.0000e-04\n",
            "Epoch 129/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1472 - dice_coef: 0.8528 - iou: 0.7435 - recall: 0.3215 - precision: 0.9932\n",
            "Epoch 129: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1472 - dice_coef: 0.8528 - iou: 0.7435 - recall: 0.3215 - precision: 0.9932 - val_loss: 0.2491 - val_dice_coef: 0.7509 - val_iou: 0.6019 - val_recall: 0.3040 - val_precision: 0.9555 - lr: 1.0000e-04\n",
            "Epoch 130/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1475 - dice_coef: 0.8525 - iou: 0.7431 - recall: 0.3214 - precision: 0.9932\n",
            "Epoch 130: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1475 - dice_coef: 0.8525 - iou: 0.7431 - recall: 0.3214 - precision: 0.9932 - val_loss: 0.2457 - val_dice_coef: 0.7543 - val_iou: 0.6063 - val_recall: 0.3061 - val_precision: 0.9580 - lr: 1.0000e-04\n",
            "Epoch 131/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1478 - dice_coef: 0.8522 - iou: 0.7426 - recall: 0.3216 - precision: 0.9930\n",
            "Epoch 131: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1478 - dice_coef: 0.8522 - iou: 0.7426 - recall: 0.3216 - precision: 0.9930 - val_loss: 0.2424 - val_dice_coef: 0.7576 - val_iou: 0.6106 - val_recall: 0.3104 - val_precision: 0.9589 - lr: 1.0000e-04\n",
            "Epoch 132/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1476 - dice_coef: 0.8524 - iou: 0.7429 - recall: 0.3213 - precision: 0.9932\n",
            "Epoch 132: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1476 - dice_coef: 0.8524 - iou: 0.7429 - recall: 0.3213 - precision: 0.9932 - val_loss: 0.2423 - val_dice_coef: 0.7577 - val_iou: 0.6107 - val_recall: 0.3106 - val_precision: 0.9610 - lr: 1.0000e-04\n",
            "Epoch 133/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1469 - dice_coef: 0.8531 - iou: 0.7439 - recall: 0.3211 - precision: 0.9935\n",
            "Epoch 133: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1469 - dice_coef: 0.8531 - iou: 0.7439 - recall: 0.3211 - precision: 0.9935 - val_loss: 0.2476 - val_dice_coef: 0.7524 - val_iou: 0.6039 - val_recall: 0.3082 - val_precision: 0.9610 - lr: 1.0000e-04\n",
            "Epoch 134/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1468 - dice_coef: 0.8532 - iou: 0.7441 - recall: 0.3217 - precision: 0.9934\n",
            "Epoch 134: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1468 - dice_coef: 0.8532 - iou: 0.7441 - recall: 0.3217 - precision: 0.9934 - val_loss: 0.2499 - val_dice_coef: 0.7501 - val_iou: 0.6009 - val_recall: 0.3061 - val_precision: 0.9621 - lr: 1.0000e-04\n",
            "Epoch 135/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1468 - dice_coef: 0.8532 - iou: 0.7442 - recall: 0.3215 - precision: 0.9934\n",
            "Epoch 135: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1468 - dice_coef: 0.8532 - iou: 0.7442 - recall: 0.3215 - precision: 0.9934 - val_loss: 0.2479 - val_dice_coef: 0.7521 - val_iou: 0.6035 - val_recall: 0.3043 - val_precision: 0.9637 - lr: 1.0000e-04\n",
            "Epoch 136/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1463 - dice_coef: 0.8537 - iou: 0.7450 - recall: 0.3214 - precision: 0.9936\n",
            "Epoch 136: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1463 - dice_coef: 0.8537 - iou: 0.7450 - recall: 0.3214 - precision: 0.9936 - val_loss: 0.2476 - val_dice_coef: 0.7524 - val_iou: 0.6038 - val_recall: 0.3029 - val_precision: 0.9636 - lr: 1.0000e-04\n",
            "Epoch 137/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1456 - dice_coef: 0.8544 - iou: 0.7460 - recall: 0.3217 - precision: 0.9937\n",
            "Epoch 137: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1456 - dice_coef: 0.8544 - iou: 0.7460 - recall: 0.3217 - precision: 0.9937 - val_loss: 0.2498 - val_dice_coef: 0.7502 - val_iou: 0.6009 - val_recall: 0.3016 - val_precision: 0.9624 - lr: 1.0000e-04\n",
            "Epoch 138/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1454 - dice_coef: 0.8546 - iou: 0.7463 - recall: 0.3222 - precision: 0.9937\n",
            "Epoch 138: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1454 - dice_coef: 0.8546 - iou: 0.7463 - recall: 0.3222 - precision: 0.9937 - val_loss: 0.2512 - val_dice_coef: 0.7488 - val_iou: 0.5991 - val_recall: 0.3010 - val_precision: 0.9615 - lr: 1.0000e-04\n",
            "Epoch 139/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1458 - dice_coef: 0.8542 - iou: 0.7456 - recall: 0.3218 - precision: 0.9937\n",
            "Epoch 139: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1458 - dice_coef: 0.8542 - iou: 0.7456 - recall: 0.3218 - precision: 0.9937 - val_loss: 0.2473 - val_dice_coef: 0.7527 - val_iou: 0.6041 - val_recall: 0.3051 - val_precision: 0.9597 - lr: 1.0000e-04\n",
            "Epoch 140/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1457 - dice_coef: 0.8543 - iou: 0.7458 - recall: 0.3214 - precision: 0.9938\n",
            "Epoch 140: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1457 - dice_coef: 0.8543 - iou: 0.7458 - recall: 0.3214 - precision: 0.9938 - val_loss: 0.2422 - val_dice_coef: 0.7578 - val_iou: 0.6107 - val_recall: 0.3141 - val_precision: 0.9552 - lr: 1.0000e-04\n",
            "Epoch 141/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1456 - dice_coef: 0.8544 - iou: 0.7460 - recall: 0.3212 - precision: 0.9938\n",
            "Epoch 141: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1456 - dice_coef: 0.8544 - iou: 0.7460 - recall: 0.3212 - precision: 0.9938 - val_loss: 0.2426 - val_dice_coef: 0.7574 - val_iou: 0.6102 - val_recall: 0.3161 - val_precision: 0.9549 - lr: 1.0000e-04\n",
            "Epoch 142/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1453 - dice_coef: 0.8547 - iou: 0.7464 - recall: 0.3215 - precision: 0.9939\n",
            "Epoch 142: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1453 - dice_coef: 0.8547 - iou: 0.7464 - recall: 0.3215 - precision: 0.9939 - val_loss: 0.2465 - val_dice_coef: 0.7535 - val_iou: 0.6052 - val_recall: 0.3122 - val_precision: 0.9563 - lr: 1.0000e-04\n",
            "Epoch 143/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1454 - dice_coef: 0.8546 - iou: 0.7463 - recall: 0.3217 - precision: 0.9937\n",
            "Epoch 143: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 65s 2s/step - loss: 0.1454 - dice_coef: 0.8546 - iou: 0.7463 - recall: 0.3217 - precision: 0.9937 - val_loss: 0.2457 - val_dice_coef: 0.7543 - val_iou: 0.6063 - val_recall: 0.3098 - val_precision: 0.9588 - lr: 1.0000e-04\n",
            "Epoch 144/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1452 - dice_coef: 0.8548 - iou: 0.7466 - recall: 0.3218 - precision: 0.9938\n",
            "Epoch 144: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1452 - dice_coef: 0.8548 - iou: 0.7466 - recall: 0.3218 - precision: 0.9938 - val_loss: 0.2445 - val_dice_coef: 0.7555 - val_iou: 0.6078 - val_recall: 0.3091 - val_precision: 0.9597 - lr: 1.0000e-04\n",
            "Epoch 145/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1448 - dice_coef: 0.8552 - iou: 0.7472 - recall: 0.3218 - precision: 0.9940\n",
            "Epoch 145: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1448 - dice_coef: 0.8552 - iou: 0.7472 - recall: 0.3218 - precision: 0.9940 - val_loss: 0.2475 - val_dice_coef: 0.7525 - val_iou: 0.6040 - val_recall: 0.3079 - val_precision: 0.9588 - lr: 1.0000e-04\n",
            "Epoch 146/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1443 - dice_coef: 0.8557 - iou: 0.7479 - recall: 0.3218 - precision: 0.9941\n",
            "Epoch 146: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1443 - dice_coef: 0.8557 - iou: 0.7479 - recall: 0.3218 - precision: 0.9941 - val_loss: 0.2515 - val_dice_coef: 0.7485 - val_iou: 0.5989 - val_recall: 0.3058 - val_precision: 0.9585 - lr: 1.0000e-04\n",
            "Epoch 147/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1442 - dice_coef: 0.8558 - iou: 0.7481 - recall: 0.3217 - precision: 0.9941\n",
            "Epoch 147: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1442 - dice_coef: 0.8558 - iou: 0.7481 - recall: 0.3217 - precision: 0.9941 - val_loss: 0.2513 - val_dice_coef: 0.7487 - val_iou: 0.5992 - val_recall: 0.3074 - val_precision: 0.9577 - lr: 1.0000e-04\n",
            "Epoch 148/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1441 - dice_coef: 0.8559 - iou: 0.7483 - recall: 0.3215 - precision: 0.9942\n",
            "Epoch 148: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 66s 2s/step - loss: 0.1441 - dice_coef: 0.8559 - iou: 0.7483 - recall: 0.3215 - precision: 0.9942 - val_loss: 0.2500 - val_dice_coef: 0.7500 - val_iou: 0.6008 - val_recall: 0.3096 - val_precision: 0.9564 - lr: 1.0000e-04\n",
            "Epoch 149/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1442 - dice_coef: 0.8558 - iou: 0.7481 - recall: 0.3219 - precision: 0.9941\n",
            "Epoch 149: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 67s 2s/step - loss: 0.1442 - dice_coef: 0.8558 - iou: 0.7481 - recall: 0.3219 - precision: 0.9941 - val_loss: 0.2500 - val_dice_coef: 0.7500 - val_iou: 0.6008 - val_recall: 0.3076 - val_precision: 0.9577 - lr: 1.0000e-04\n",
            "Epoch 150/150\n",
            "40/40 [==============================] - ETA: 0s - loss: 0.1439 - dice_coef: 0.8561 - iou: 0.7486 - recall: 0.3222 - precision: 0.9942\n",
            "Epoch 150: val_loss did not improve from 0.23187\n",
            "40/40 [==============================] - 64s 2s/step - loss: 0.1439 - dice_coef: 0.8561 - iou: 0.7486 - recall: 0.3222 - precision: 0.9942 - val_loss: 0.2522 - val_dice_coef: 0.7478 - val_iou: 0.5979 - val_recall: 0.3050 - val_precision: 0.9575 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg\")))\n",
        "    return x, y\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=-1)              ## (512, 512, 1)\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(X, Y, batch_size=2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(4)\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory to save files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    batch_size = 4\n",
        "    lr = 0.001\n",
        "    num_epochs = 150\n",
        "    model_path = os.path.join(\"/content/drive/MyDrive/files\", \"lastQ1model.h5\")\n",
        "    csv_path = os.path.join(\"/content/drive/MyDrive/files\", \"lastQ1data.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    dataset_path = \"/content/drive/MyDrive/finaldata\"\n",
        "    train_path = os.path.join(dataset_path, \"train\")\n",
        "    valid_path = os.path.join(dataset_path, \"val\")\n",
        "\n",
        "    train_x, train_y = load_data(train_path)\n",
        "    train_x, train_y = shuffling(train_x, train_y)\n",
        "    valid_x, valid_y = load_data(valid_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_setps = len(valid_x)//batch_size\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_setps += 1\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = build_unet((H, W, 3))\n",
        "    model.compile(loss=dice_loss, optimizer=Adam(lr), metrics=[dice_coef, iou, Recall(), Precision()])\n",
        "    # model.summary()\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.01, patience=5, min_lr= 0.0001, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=150, restore_best_weights=False)\n",
        "    ]\n",
        "    history =  model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_setps,\n",
        "        callbacks=callbacks\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKU97kq_maru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8fc099-23e9-4f51-b4d8-d7be9b44b144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 10s 10s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 1/20 [00:13<04:07, 13.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 2/20 [00:21<03:07, 10.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 3/20 [00:32<03:01, 10.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 4/20 [00:44<02:55, 10.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 9s 9s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 5/20 [00:54<02:40, 10.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 6/20 [01:02<02:19,  9.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 7/20 [01:11<02:02,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 8/20 [01:22<01:59,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 9/20 [01:33<01:53, 10.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 10/20 [01:44<01:45, 10.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 11/20 [01:52<01:28,  9.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 12/20 [02:01<01:15,  9.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 13/20 [02:12<01:09,  9.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 14/20 [02:20<00:57,  9.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 15/20 [02:29<00:46,  9.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 16/20 [02:40<00:39,  9.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 17/20 [02:49<00:28,  9.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 18/20 [02:57<00:18,  9.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 19/20 [03:20<00:13, 13.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 8s 8s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [03:31<00:00, 10.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.41568\n",
            "F1: 0.23361\n",
            "Jaccard: 0.13235\n",
            "Recall: 0.13249\n",
            "Precision: 0.99241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#Evaluation\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "H = 512\n",
        "W = 512\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def read_image(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  ## (512, 512)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def load_data(path):\n",
        "    x = sorted(glob(os.path.join(path, \"image\", \"*.jpg_\")))\n",
        "    y = sorted(glob(os.path.join(path, \"mask\", \"*.jpg_\")))\n",
        "    return x, y\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    line = np.ones((H, 10, 3)) * 255     # 10 pixel white line to separate the images\n",
        "\n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1) * 255\n",
        "\n",
        "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred], axis=1)    #concatinated images\n",
        "    cv2.imwrite(save_image_path, cat_images)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Save the results in this folder \"\"\"\n",
        "    create_dir(\"results\")\n",
        "\n",
        "    \"\"\" Load the model \"\"\"\n",
        "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
        "        model = tf.keras.models.load_model(\"/content/drive/MyDrive/files/lastQ1model.h5\")\n",
        "\n",
        "    \"\"\" Load the dataset \"\"\"\n",
        "    dataset_path = os.path.join(\"/content/drive/MyDrive/test\")\n",
        "    test_x, test_y = load_data(dataset_path)\n",
        "\n",
        "    \"\"\" Make the prediction and calculate the metrics values \"\"\"\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "      \"\"\" Extracting name \"\"\"\n",
        "      name = x.split(\"/\")[-1].split(\".\")[0]\n",
        "            \n",
        "      #Read the image and mask\n",
        "      ori_x, x = read_image(x)\n",
        "      ori_y, y = read_mask(y)\n",
        "\n",
        "      #Prediction \n",
        "      y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
        "      y_pred = y_pred > 0.5   # the threshold to make it 0 or 1 predict\n",
        "      y_pred = y_pred.astype(np.int32)\n",
        "      y_pred = np.squeeze(y_pred, axis=-1)\n",
        "\n",
        "      # Saving the images\n",
        "      save_image_path = f\"/content/drive/MyDrive/finalresult/proimage/{name}.jpg\"\n",
        "      save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "   \n",
        "           \n",
        "      # Flatten the array\n",
        "      y = y.flatten()\n",
        "      y_pred = y_pred.flatten()\n",
        "\n",
        "      #Calculate the metrics \n",
        "      acc_value = accuracy_score(y, y_pred)\n",
        "      f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "      SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=0)\n",
        "    \n",
        "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "    print(f\"F1: {score[1]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
        "    print(f\"Recall: {score[3]:0.5f}\")\n",
        "    print(f\"Precision: {score[4]:0.5f}\")\n",
        "    \n",
        "\n",
        "    #Saving \n",
        "    df = pd.DataFrame(SCORE, columns=[\"Image\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"/content/drive/MyDrive/finalresult/proscore.csv\")\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HEZgrqBmauw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nwmrhR2max6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYCvZ8qUDPYh"
      },
      "outputs": [],
      "source": [
        "#model atrous convolution\n",
        "import tensorflow as tf\n",
        "import numpy as np,sys\n",
        "from  scipy.signal import convolve2d\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", dilation_rate = (2,2))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    \n",
        "    x = Conv2D(num_filters, 3, padding=\"same\", dilation_rate = (2,2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    s = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(s)\n",
        "    return s, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, dilation_rate = (2,2), padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    \"\"\"input layer\"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    \"\"\"Encoder\"\"\"\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    \"\"\"Bottleneck\"\"\"\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    \"\"\"Decoedr\"\"\"\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"Atrous_UNET\")\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (512, 512, 3)\n",
        "    model = build_unet(input_shape)\n",
        "    model.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}